# Modelo de LLM

## Modelo

Gemini 1.5-Flash via API

## Justificativa

1. Escalabilidade: A API oferece recursos computacionais praticamente ilimitados, permitindo lidar com picos de demanda e processar grandes volumes de dados.

2. Atualizações constantes: A API é constantemente atualizada com os últimos avanços, assim o projeto sempre tem acesso às melhores capacidades do modelo.

3. Facilidade de uso: Não é necessário gerenciar infraestrutura local, e a API é bem documentada.

4. Janela de contexto: O Gemini 1.5-Flash possui uma janela de contexto de aproximadamente 1 milhão de Tokens. Modelos Open Source com janelas de contexto grandes requerem muito recurso computacional, sendo necessário múltiplas GPUs para rodá-los.

5. Integração: Grandes frameworks de LLM como LLama Index e LangChain possuem integração com o Gemini.
