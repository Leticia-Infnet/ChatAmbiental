import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import os
import numpy as np
import nltk
import re
from wordcloud import WordCloud
from PIL import Image

st.set_page_config(
    page_title='Observat√≥rio da Conserva√ß√£o',
    page_icon='üê∏'
)


@st.cache_data
def csv_news_to_df(filename) -> pd.DataFrame:
    '''
    Fun√ß√£o que l√™ o arquivo CSV com os resultados da coleta de not√≠cias e retorna um DataFrame.

    Returns:
    df (pd.DataFrame): DataFrame com os resultados da coleta de not√≠cias.
    '''
    df = pd.read_csv(os.path.abspath(
        os.path.join('.', 'Data', 'news_data', filename)))
    return df


@st.cache_data
def remove_stopwords(df: pd.DataFrame) -> str:
    '''
    Fun√ß√£o que tokeniza o texto das not√≠cias e retorna uma string com as palavras filtradas.

    Args:
    df (pd.DataFrame): DataFrame com as not√≠cias.

    Returns:
    filtered_words (str): String com as palavras filtradas.
    '''
    nltk.download('stopwords')
    stopwords = set(nltk.corpus.stopwords.words('portuguese'))

    words = [re.sub(r'[^\w\s]|[\d]', '', word.lower().strip())
             for line in df['content']
             for word in line.split()]

    filtered_words = [
        word for word in words if word and word not in stopwords and (len(word) > 3 or word == 'sul')]

    return ' '.join(filtered_words)


@st.cache_data
def generate_wordcloud(text: str) -> tuple:
    '''
    Fun√ß√£o que gera a nuvem de palavras e retorna a figura e o eixo.

    Args:
    text (str): Texto das not√≠cias.

    Returns:
    tuple: (figura, eixo) do matplotlib
    '''
    frog_mask = np.array(Image.open(
        os.path.abspath(os.path.join('.', 'Data', 'images', 'frog.png'))))

    stopwords = ['brasil', 'ano', 'ainda',
                 '√°rea', 'estado', 'sobre',
                 'segundo', 'projeto', 'disse',
                 'todo', 'outro', 'outra',
                 'apenas', 'pode', 'grande',
                 'desde', 'gente', 'regi√£o',
                 'proposta', 'forma', 'al√©m',
                 'toda', 'onde', '√°reas',
                 'processo', 'a√ß√µes', 'esp√©cie',
                 'pa√≠s', 'maior', 'pessoa',
                 'munic√≠pio', 'nova', 'cidade',
                 'dado', 'sendo', 'anos',
                 'estudo', 'bioma', 'outras',
                 'podem', 'esp√©cies', 'parte',
                 'acordo', 'ent√£o', 'caso',
                 'pessoas', 'porque', 'total',
                 'desse', '√≥rg√£o', 'territ√≥rio',
                 'outros', 'trabalho', 'ap√≥s',
                 'dados', 'milh√µes', 'n√∫mero',
                 'animais', 'impacto', 'parque',
                 'contra', 'atividade', 'pesquisadores',
                 'todos', 'medida', 'assim',
                 'munic√≠pios', 'ambiental', 'governo',
                 'nacional', 'problema', 'disso',
                 'hectare', 'hectares', 'plano',
                 'pol√≠tica', 'federal', 'prote√ß√£o',
                 'presidente', 'dessa', 'estados',
                 'empresa', 'cada', 'afirmou',
                 'conta', 'sistema', 'instituto',
                 'durante', 'exemplo', 'dentro',
                 'rela√ß√£o', 'direito', 'afirmou',
                 'brasileiro', 'servidores', 'importante',
                 'pesquisa', 'novo', 'tema']

    wordcloud = WordCloud(width=800,
                          height=400,
                          scale=1.5,
                          background_color='white',
                          colormap='Dark2',
                          contour_width=3,
                          stopwords=stopwords,
                          contour_color='green',
                          mask=frog_mask).generate(text)

    fig, ax = plt.subplots(figsize=(10, 6))
    ax.imshow(wordcloud, interpolation='bilinear')
    ax.set_axis_off()
    return fig, ax


def create_word_cloud(text: str) -> None:
    '''
    Fun√ß√£o que cria e exibe a nuvem de palavras no Streamlit.

    Args:
    text (str): Texto das not√≠cias.

    Returns:
    None
    '''
    st.markdown('## Nuvem de Palavras:snow_cloud:')
    st.markdown('''A nuvem de palavras abaixo foi gerada a partir do conte√∫do das
                not√≠cias do ano de 2024 do site [((o))eco](https://www.oeco.org.br/).''')
    with st.spinner('Aguarde, carregando dados...'):
        fig, _ = generate_wordcloud(text)
        st.pyplot(fig)


def app():
    '''
    Fun√ß√£o principal que cria a aplica√ß√£o Streamlit.
    '''
    st.title('Observat√≥rio da Conserva√ß√£o:frog:')
    st.markdown('<div style="text-align: justify;">A conserva√ß√£o da biodiversidade e dos recursos naturais √© um tema de extrema import√¢ncia na sociedade atual. V√°rios ODS est√£o diretamente relacionados √† conserva√ß√£o, como o ODS 13 (A√ß√£o contra a mudan√ßa global do clima), ODS 14 (Vida na √°gua) e ODS 15 (Vida terrestre). Em vista desse cen√°rio, o Observat√≥rio da Conserva√ß√£o foi criado para disponibilizar an√°lises e informa√ß√µes sobre a conserva√ß√£o da biodiversidade e dos recursos naturais no Brasil.</div>', unsafe_allow_html=True)
    df_news = csv_news_to_df('news_results.csv')
    text = remove_stopwords(df_news)
    create_word_cloud(text)


app()
